{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================\n",
      "\n",
      "HELLO 'Shalin Karavadia', YOU ARE AN AUTHORISED USER \n",
      "\n",
      "==========================================================\n",
      "\n",
      "\n",
      "NOTE 1 :- This Application supported files types and their extensions are :- \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "1. Images [.png, .jpg, .jpeg, .jfif] \n",
      "2. PDF    [.pdf = Searchable as well as Scanned]\n",
      "3. Text   [.text]\n",
      "4. Word   [.docx] -> Here, .doc is not supported, So, please save the file from .doc (Microsoft 97-2003) -> .docx (word document) and then again run the application\n",
      "\n",
      "\n",
      "NOTE 2 :- The Expected Accurcacy Percentage(%) of different files are mentioned below :- \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "|-----------------------------------------------|\n",
      "|     FILE TYPES       |          ACCURACY      |\n",
      "|-----------------------------------------------|\n",
      "|        Text          |          100 %         |\n",
      "|     PDF, Word        |   Approximately  90 %  |\n",
      "|       Images         |   Approximately  80 %  |\n",
      "|-----------------------------------------------|\n",
      "\n",
      "\n",
      "NOTE 3 :- Below is the List of Keywords program will search :- \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "['internet protocol', 'alternate dns', '34,200', 'mbbs', 'monday', 'ambattur', 'venkateshwara private', 'rohtak panipat', '82335', 'shalin karavadia', 'tuesday', 'hello', 'recommendation', 'observations']\n",
      "\n",
      "THANK YOU FOR YOUR TIME !!\n",
      "PROGRAM HAS STARTED TO EXECUTE, CURRENTLY IN PROCESSING MODE.....\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\PyPDF2\\_utils.py:76: UserWarning: isString is deprecated and will be removed in PyPDF2 2.0.0.\n",
      "  warnings.warn(DEPR_MSG_NO_REPLACEMENT.format(\"isString\"))\n",
      "\n",
      "UserWarning: namedDestinations will be removed in PyPDF2 2.0.0. Use `named_destinations` instead. [_reader.py:519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing and operation on file :- '2= INFOBLOX SECURITY HARDENING PARAMETERS WITH PATHS' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'advantech-fwa-3260-annotated=PNG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Audit report - Network Security  FY 2022  v1=9' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'DNS Hardening Document=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'dr dane certfcate=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Firewall Hardening Document=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'how-dns-works=PNG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'how-route-53-routes-traffic=8D313C7DA075C3C7303AAEF32E89B5D0B7885E7C' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'ICICI_Bank_Audit_Report_LCG_ West_Zone_Q1_Q2_FY2022=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'ICICI_Bank_Audit_Report_New_York_Corporate Banking_FY2022=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'ICICI_Bank_IS_Audit_Report_Digitisation_Retail Liability & related operations_FY2021_ver01=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'INFOBLOX Security Hardening parameters with paths=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'ISSP V 12=0' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Jio - 1=PNG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Jio - 2=PNG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Jio Receipt=PNG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'KAF-Possible Data Leakage methods=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'L3-Key Audit Findings (KAFs) - Information System audit - Black Box Testing_FY2022=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'L3-Key Audit Findings (KAFs) - IT Governance and Cyber Security Bahrain Branch_FY2022=DOCX File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'L3-Key Audit Findings (KAFs) - IT Governance And Cyber Security_FY2022=DOCX File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'LAN IP Change=PNG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Lavelle Physical device=JFIF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Load Balancer Hardening Document=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Picture 1=JFIF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Picture 2=PNG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Picture 3=PNG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Picture 4=PNG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Recommended SOP=DOCX File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Recommended SOP_DNS=DOCX File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'report=TXT File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Router Hardening Document=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Sample=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Subway - 1=PNG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Subway - 2=PNG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Subway Receipt=PNG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Switch Hardening Document=PDF File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Telephone_Expense_Declaration_January-March 2018=JPG File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'Testing=TXT File' Completed\n",
      "\n",
      "\n",
      "Processing and operation on file :- 'WAF Hardening Document=PDF File' Completed\n",
      "\n",
      "\n",
      " EXECUTION OF PROGRAM COMPLETED \n",
      "\n",
      "#######  THANK YOU  ############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  FINAL WITH TASK 1  \"\"\"\n",
    "\n",
    "\"\"\"  THIS FINAL PROGRAM WILL NOT WORK WITH .DOC FILES , BUT WILL WORK WITH SCANNED PDFs \"\"\"\n",
    "\n",
    "# VERSION - 3 :- PRIVILEDGES EQUATION ALSO INCLUDED\n",
    "\n",
    "import subprocess as sp                # Find Hostname from CMD from computer\n",
    "import pandas as pd                    # For dataframes\n",
    "import os                              # To collect all the files from OS\n",
    "import cv2                             # Text extraction from IMAGE - 1 library\n",
    "import pytesseract                     # Text extraction from IMAGE - 2 library\n",
    "import fitz                            # Extract text from PDF file\n",
    "import msoffcrypto                     # Open the password protected excel file by inserting password. - 1\n",
    "import io                              # Open the password protected excel file by inserting password. - 2\n",
    "import docx2txt                        # Extract text from WORD file \n",
    "import shutil                          # delete the folder containing files and data\n",
    "from PyPDF2 import PdfFileMerger\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "##################################################\n",
    "# Here, deleting all the previously generated text files(dir1), then all extra files (dir2) and lastly final output(dir3) \n",
    "\n",
    "dir1 = \"D:\\Innovation Team\\Text Search Utility\\Output\\Converted Text Files\"\n",
    "for f1 in os.listdir(dir1):\n",
    "    os.remove(os.path.join(dir1, f1))\n",
    "\n",
    "dir2 = \"D:\\Innovation Team\\Text Search Utility\\Output\\Converted Searchable PDF\"\n",
    "for f2 in os.listdir(dir2):\n",
    "    os.remove(os.path.join(dir2, f2))\n",
    "    \n",
    "myfile1 = \"D:\\Innovation Team\\Text Search Utility\\Output\\Output.xlsx\"\n",
    "if os.path.isfile(myfile1):\n",
    "    os.remove(myfile1)\n",
    "    \n",
    "myfile2 = \"D:\\Innovation Team\\Text Search Utility\\Output\\Summary.txt\"\n",
    "if os.path.isfile(myfile2):\n",
    "    os.remove(myfile2)\n",
    "    \n",
    "##################################################\n",
    "# Below This is the Part, Wherein we are extracting the list of all admin users from password protected excel sheet.\n",
    "\n",
    "temp = io.BytesIO()\n",
    "\n",
    "with open(r\"D:\\Innovation Team\\Text Search Utility\\Setup\\LIST.xlsx\", 'rb') as f:\n",
    "    excel = msoffcrypto.OfficeFile(f)\n",
    "    excel.load_key('Shalin$Vishal')\n",
    "    excel.decrypt(temp)\n",
    "\n",
    "Data_Frame = pd.read_excel(temp)\n",
    "del temp\n",
    "Admin_Users = list(Data_Frame[\"Asset Number\"])\n",
    "\n",
    "###################################################\n",
    "# Here, we are finding Assetcode from CMD and command in CMD is \"hostname\"\n",
    "\n",
    "Asset_code = sp.getoutput('hostname')\n",
    "\n",
    "###################################################\n",
    "# Here, searching for asset name in the list of admin users, If asset code found in admin user list then permit to run the application or else end the program.\n",
    "\n",
    "if Asset_code in Admin_Users:\n",
    "    \n",
    "    row = Data_Frame[Data_Frame['Asset Number']==Asset_code]\n",
    "    Asset_Number_Name = list(row['Name'])[0]\n",
    "    \n",
    "    print()\n",
    "    print(\"==========================================================\")\n",
    "    print()\n",
    "    print(\"HELLO '\"+Asset_Number_Name+\"', YOU ARE AN AUTHORISED USER \")\n",
    "    print()\n",
    "    print(\"==========================================================\")\n",
    "    print()\n",
    "    \n",
    "    # Normally Run the program.\n",
    "    \n",
    "    Search_file = open(r\"D:\\Innovation Team\\Text Search Utility\\Search.txt\", 'r', encoding=\"utf8\")\n",
    "    \n",
    "    print()\n",
    "    print(\"NOTE 1 :- This Application supported files types and their extensions are :- \")\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print()\n",
    "    print(\"1. Images [.png, .jpg, .jpeg, .jfif] \")\n",
    "    print(\"2. PDF    [.pdf = Searchable as well as Scanned]\") \n",
    "    print(\"3. Text   [.text]\")\n",
    "    print(\"4. Word   [.docx] -> Here, .doc is not supported, So, please save the file from .doc (Microsoft 97-2003) -> .docx (word document) and then again run the application\")\n",
    "    print()\n",
    "    print()\n",
    "    print(\"NOTE 2 :- The Expected Accurcacy Percentage(%) of different files are mentioned below :- \")\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print()\n",
    "    print(\"|-----------------------------------------------|\")\n",
    "    print(\"|     FILE TYPES       |          ACCURACY      |\")\n",
    "    print(\"|-----------------------------------------------|\")\n",
    "    print(\"|        Text          |          100 %         |\")\n",
    "    print(\"|     PDF, Word        |   Approximately  90 %  |\") \n",
    "    print(\"|       Images         |   Approximately  80 %  |\") \n",
    "    print(\"|-----------------------------------------------|\")\n",
    "    print()\n",
    "\n",
    "    A = []\n",
    "    for line in Search_file:\n",
    "        A.append(line.replace(\"\\n\",\"\").lower().strip())\n",
    "\n",
    "    print()\n",
    "    print(\"NOTE 3 :- Below is the List of Keywords program will search :- \")\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "    print()  \n",
    "    print(A)\n",
    "    print()\n",
    "    print(\"THANK YOU FOR YOUR TIME !!\")\n",
    "    print(\"PROGRAM HAS STARTED TO EXECUTE, CURRENTLY IN PROCESSING MODE.....\")\n",
    "    print()\n",
    "\n",
    "    path = r\"D:\\Innovation Team\\Text Search Utility\\Input\"  # path of Scanned Images.\n",
    "\n",
    "    os.chdir(path) \n",
    "\n",
    "    Count_List = []     # List created to capture the Count of word findings from all the scanned files.\n",
    "\n",
    "    def read_text_file(file_path):       # here, we are reading  all the scanned images one by one and extracting text from each.\n",
    "\n",
    "        pytesseract.pytesseract.tesseract_cmd = r\"D:\\Innovation Team\\Text Search Utility\\Setup\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "        # Load image, grayscale, and Otsu's threshold\n",
    "        image = cv2.imread(file_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # Remove horizontal lines\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50,1))\n",
    "        detect_horizontal = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
    "        cnts = cv2.findContours(detect_horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "        for c in cnts:\n",
    "            cv2.drawContours(thresh, [c], -1, (0,0,0), 2)\n",
    "\n",
    "        # Remove vertical lines\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,15))\n",
    "        detect_vertical = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n",
    "        cnts = cv2.findContours(detect_vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "        for c in cnts:\n",
    "            cv2.drawContours(thresh, [c], -1, (0,0,0), 3)\n",
    "\n",
    "        # Dilate to connect text and remove dots\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10,1))\n",
    "        dilate = cv2.dilate(thresh, kernel, iterations=2)\n",
    "        cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area < 500:\n",
    "                cv2.drawContours(dilate, [c], -1, (0,0,0), -1)\n",
    "\n",
    "        # Bitwise-and to reconstruct image\n",
    "        result = cv2.bitwise_and(image, image, mask=dilate)\n",
    "        result[dilate==0] = (255,255,255)\n",
    "\n",
    "        # OCR\n",
    "        data = pytesseract.image_to_string(result, lang='eng',config='--psm 6')\n",
    "        #data = data.lower()\n",
    "        f= open(\"D:\\\\Innovation Team\\\\Text Search Utility\\\\Output\\\\Converted Text Files\\\\\"+File_Name+\"=\"+Extensions+\".txt\",\"w+\", encoding=\"utf8\")\n",
    "        f.write(data)\n",
    "        f.close()\n",
    "        #print(\"############################################\")\n",
    "\n",
    "    D = 0\n",
    "    List_of_Extensions = []\n",
    "    for file in os.listdir():  \n",
    "        \n",
    "        Split = os.path.splitext(file)\n",
    "        List_of_Extensions.append(Split[1])\n",
    "        \n",
    "        if file.endswith(\".png\") or file.endswith(\".jfif\") or file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".docx\") or file.endswith(\".pdf\") or file.endswith(\".PDF\") or file.endswith(\".txt\"):   # only images with these extensions will be picked for opeartion\n",
    "\n",
    "            D += 1\n",
    "            file_path = f\"{path}\\{file}\"\n",
    "            I = file.index(\".\")\n",
    "            File_Name = file[:I]\n",
    "            Extensions = file[I+1:].upper() + \" File\"\n",
    "\n",
    "            if file.endswith(\".pdf\"):\n",
    "\n",
    "                with fitz.open(file_path) as doc:\n",
    "                    Content = \"\"\n",
    "                    for page in doc:\n",
    "                        Content += page.get_text()\n",
    "\n",
    "                if Content == \"\":\n",
    "                    \n",
    "                    images = convert_from_path(file_path, 500, poppler_path=r'D:\\Innovation Team\\Text Search Utility\\Setup\\poppler-0.68.0\\bin')\n",
    "\n",
    "                    New_folder_Path = r\"D:\\Innovation Team\\Text Search Utility\\Setup\\Images\"         \n",
    "                    if not os.path.exists(New_folder_Path):\n",
    "                        os.mkdir(New_folder_Path)\n",
    "\n",
    "                    for i, image in enumerate(images):\n",
    "                        image.save(\"D:\\\\Innovation Team\\\\Text Search Utility\\\\Setup\\\\Images\\\\\"+str(i)+\".png\", \"PNG\")\n",
    "\n",
    "                    pytesseract.pytesseract.tesseract_cmd = r\"D:\\Innovation Team\\Text Search Utility\\Setup\\Tesseract-OCR\\tesseract.exe\"\n",
    "                    TESSDATA_PREFIX = r\"D:\\Innovation Team\\Text Search Utility\\Setup\\Tesseract-OCR\"\n",
    "                    tessdata_dir_config = '--tessdata-dir \"D:\\\\Innovation Team\\\\Text Search Utility\\\\Setup\\\\Tesseract-OCR\\\\tessdata\"'\n",
    "\n",
    "                    merger = PdfFileMerger()\n",
    "\n",
    "                    Outline = r\"D:\\\\Innovation Team\\\\Text Search Utility\\\\Output\\\\Converted Searchable PDF\\\\\"+File_Name+\"= Converted to Searchable PDF\"+\".pdf\"\n",
    "                    \n",
    "                    f = open(Outline, \"ab\")\n",
    "\n",
    "                    for file in os.listdir(New_folder_Path):  \n",
    "\n",
    "                        if file.endswith(\".png\"):        \n",
    "                            filepath = os.path.join(New_folder_Path, file)\n",
    "\n",
    "                            with Image.open(filepath) as img:\n",
    "\n",
    "                                result = pytesseract.image_to_pdf_or_hocr(img, lang=\"eng\", config=tessdata_dir_config)\n",
    "                                pdf_file_in_memory = io.BytesIO(result)        \n",
    "                                merger.append(pdf_file_in_memory)\n",
    "\n",
    "                    merger.write(Outline)\n",
    "                    merger.close()\n",
    "                    f.close()\n",
    "                    shutil.rmtree(New_folder_Path)    # Here, we are removing the directotries which are created after conversion it.\n",
    "\n",
    "                    with fitz.open(Outline) as doc:\n",
    "                        Content = \"\"\n",
    "                        for page in doc:\n",
    "                            Content += page.get_text()\n",
    "\n",
    "                    f = open(\"D:\\\\Innovation Team\\\\Text Search Utility\\\\Output\\\\Converted Text Files\\\\\"+File_Name+\"=\"+Extensions+\".txt\",\"w+\", encoding=\"utf-8\")  # Made new text file \n",
    "                    f.write(Content)         # write the text extract into newly created text file.\n",
    "                    f.close()\n",
    "                    \n",
    "                else:\n",
    "                    f = open(\"D:\\\\Innovation Team\\\\Text Search Utility\\\\Output\\\\Converted Text Files\\\\\"+File_Name+\"=\"+Extensions+\".txt\",\"w+\", encoding=\"utf-8\")  # Made new text file \n",
    "                    f.write(Content)         # write the text extract into newly created text file.\n",
    "                    f.close()\n",
    "\n",
    "            elif file.endswith(\".txt\"):\n",
    "\n",
    "                with open(file_path,'r') as firstfile, open(r\"D:\\\\Innovation Team\\\\Text Search Utility\\\\Output\\\\Converted Text Files\\\\\"+File_Name+\"=\"+Extensions+\".txt\",'w', encoding=\"utf8\") as secondfile:\n",
    "                    for line in firstfile:\n",
    "                        line = line.lower()\n",
    "                        secondfile.write(line)\n",
    "                \n",
    "            elif file.endswith(\".docx\"):\n",
    "                \n",
    "                my_text = docx2txt.process(file_path)\n",
    "\n",
    "                f= open(\"D:\\\\Innovation Team\\\\Text Search Utility\\\\Output\\\\Converted Text Files\\\\\"+File_Name+\"=\"+Extensions+\".txt\", \"w+\", encoding=\"utf8\")\n",
    "                f.write(my_text)\n",
    "                f.close()\n",
    "\n",
    "            else :\n",
    "                read_text_file(file_path)\n",
    "    \n",
    "    ###########################################################################\n",
    "    # Here, we are genearting \"Sheet-2 = Summary\"\n",
    "    \n",
    "    Count = len(List_of_Extensions)\n",
    "    \n",
    "    res = {}\n",
    "    for i in List_of_Extensions:\n",
    "        res[i] = List_of_Extensions.count(i)\n",
    "    \n",
    "    res['Total Input Files Count'] = Count\n",
    "\n",
    "    D = []\n",
    "    E = []\n",
    "    F = []\n",
    "    \n",
    "    for key, val in res.items():\n",
    "        D.append(key)\n",
    "        E.append(val)\n",
    "        if key == \".doc\":\n",
    "            F.append(\"Failure (This Extensions is not supported. So, Output will not be generted of this files. To Generate the output, please save this file in .docx (word document) format and then re-run the application)\")\n",
    "        elif key == \"Total Input Files Count\":\n",
    "            F.append(\"-\")            \n",
    "        else:\n",
    "            F.append(\"Success\")\n",
    "            \n",
    "    df2 = pd.DataFrame({'Extensions': D, 'Total Count': E, 'Execution':F})   # Dataframe for Sheet-2 Generated Successfully\n",
    "    \n",
    "    ###########################################################################\n",
    "\n",
    "    \"\"\"  HERE, WE ARE RUNNING HALF THE PROGRAM, AS GENERATION OF TEXT FILES IS ALREADY DONE  \"\"\"\n",
    "    \"\"\"   PART 2 :-  CORRECT CODE FOR MULTIPLE FILES OUTPUT\"\"\"\n",
    "\n",
    "    path_text_file = r\"D:\\Innovation Team\\Text Search Utility\\Output\\Converted Text Files\"  # path of all text files we created.\n",
    "\n",
    "    os.chdir(path_text_file) \n",
    "\n",
    "    df_final = pd.DataFrame() \n",
    "\n",
    "    # Here we are creating main data frame and then furthur we will just add columns.\n",
    "    # In main dataframe we limited the number of rows to be the maximun count of \"word to find\". \n",
    "    # If value in one column less then Max_rows number, then other empty space will be filled with \"NAN\" values. \" This will not give different length of columns error.\"\n",
    "    \n",
    "    def read_text_file(file_path):               # here, we are reading the text files one by one.\n",
    "        Output = open(file_path, 'r', encoding=\"utf-8\")\n",
    "\n",
    "        line_number = 0\n",
    "        list_of_results = []\n",
    "\n",
    "        for line in Output:\n",
    "                # For each line, check if line contains the string\n",
    "            line = line.lower()\n",
    "            \n",
    "            line_number += 1\n",
    "            if string_to_search in line:       # If yes, then add the line number & line as a tuple in the list\n",
    "\n",
    "                COUNT = line.count(string_to_search)\n",
    "                list_of_results.append((File_name, string_to_search, line_number, COUNT, line.rstrip()))\n",
    "\n",
    "        if list_of_results == []:\n",
    "            list_of_results.append((File_name, string_to_search, 0, 0, \"Element Not found\"))\n",
    "\n",
    "        #print(\"Personal Output => \" +string_to_search+ \" :- \", list_of_results)\n",
    "        #print()\n",
    "\n",
    "        # Till here, we are just printing 4 differnt values into ONE LIST == \"list_of_results\"\n",
    "        # These, \"list_of_results\" will contain OUTPUT of one ONE FILE.\n",
    "\n",
    "        return list_of_results\n",
    "\n",
    "    D = 0\n",
    "    final_list = []\n",
    "    for file in os.listdir():  \n",
    "        \n",
    "        os.listdir(path)\n",
    "        \n",
    "        if file.endswith(\".txt\"):\n",
    "            D += 1\n",
    "            file_path = f\"{path_text_file}\\{file}\"\n",
    "\n",
    "            I = file.index(\".\")\n",
    "            File_name = file[:I]\n",
    "\n",
    "            Combined = []\n",
    "            for t in A:\n",
    "\n",
    "                string_to_search = t\n",
    "                #print(\"-->>  String_to_search :- \", string_to_search)\n",
    "                #print()\n",
    "                one_string_to_search_output = read_text_file(file_path)    # Here, This \"results\" contains the OUTPUT of one ONE FILE == \"list_of_results.\"\n",
    "\n",
    "                Combined.extend(one_string_to_search_output)\n",
    "            #print(\"------>>>   FINAL LIST OUTPUT FOR ONE 1 FILE \")\n",
    "            #print()\n",
    "            #print(Combined)\n",
    "            #print()\n",
    "            final_list.extend(Combined)    \n",
    "            print()\n",
    "            print(\"Processing and operation on file :- '\" + File_name + \"' Completed\")\n",
    "            print()\n",
    "     \n",
    "    ###############################################################\n",
    "    # Here, we are generating \"Sheet-1 = Final Output\" \n",
    "\n",
    "    df1 = pd.DataFrame(final_list)    # Here, making dataframe of \"final_list\"\n",
    "    delimiter = \",\"                  # Swprating all the 4 elements from one block of the list into separte columns using \"delimeter\"\n",
    "    df1[0].str.split(delimiter, expand=True)    \n",
    "    df1.columns =['File_Name', 'Element_to_Find', 'Line#', 'Count', 'Full_Line']    # Naming all the 5 columns\n",
    "    \n",
    "    df1 = df1[df1['Line#'] != 0]          # Here, we are deleting all rows which contains 0 in \"Line#\" column\n",
    "\n",
    "    ##################################################################\n",
    "    # Here, we are generating \"Sheet-3 = Search Value Count\"\n",
    "    \n",
    "    df3 = df1.groupby([\"Element_to_Find\"]).Count.sum().reset_index()\n",
    "    df3.columns = [\"Search value\", \"Count\"]\n",
    "    df3.loc[len(df3.index)] = [\"TOTAL\", df3[\"Count\"].sum()]    # Dataframe for Sheet-3 Generated Successfully\n",
    "    \n",
    "    ##################################################################\n",
    "    # Here, we are generating \"Sheet-4 = Search Value to file Count\"\n",
    "\n",
    "    df4 = df1.groupby([\"Element_to_Find\",\"File_Name\"]).Count.sum().reset_index()\n",
    "    df4.columns = [\"Search value\", \"File_Name\", \"Sum of Count\"]\n",
    "\n",
    "    ##################################################################\n",
    "    # Setting all the text align into all 4 dataframes\n",
    "    \n",
    "    df1_Final = df1.style.set_properties(**{'text-align': 'left'})\n",
    "    df2_Final = df2.style.set_properties(**{'text-align': 'left'})\n",
    "    df3_Final = df3.style.set_properties(**{'text-align': 'left'})\n",
    "    df4_Final = df4.style.set_properties(**{'text-align': 'left'})\n",
    "    \n",
    "    with pd.ExcelWriter(r\"D:\\Innovation Team\\Text Search Utility\\Output\\Output.xlsx\") as writer:\n",
    "        df1_Final.to_excel(writer, sheet_name=\"Final Output\", index=False)\n",
    "        df2_Final.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
    "        df3_Final.to_excel(writer, sheet_name=\"Search Value Count\", index=False)\n",
    "        df4_Final.to_excel(writer, sheet_name=\"Search Value to File Count\", index=False)\n",
    "\n",
    "    print()\n",
    "    print(\" EXECUTION OF PROGRAM COMPLETED \")\n",
    "    print()\n",
    "    print(\"#######  THANK YOU  ############\")\n",
    "    print()\n",
    "    \n",
    "else:\n",
    "    print(\"YOU ARE NOT AUTHORISED USER TO RUN THIS APPLICATION\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.startfile(r\"D:\\Innovation Team\\Text Search Utility\\Utility\\TextSearchUtility_V1.exe\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
